{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2cc53296-8b84-47c4-af5f-f867b1fee8ec",
    "_uuid": "717a43e8-4d98-4ee3-8072-bb175df6edba",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the \"../input/\" directory.\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('./dataset'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\envs\\test\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import jieba\n",
    "import swifter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from pypinyin import lazy_pinyin, Style, load_single_dict, load_phrases_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style = Style.TONE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\lizeda\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.019 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "with open(\"./user_dict.txt\", \"w\", encoding=\"utf8\") as fw:\n",
    "    fw.write(\"\"\"[*] 4\n",
    "[LAUGH] 4\n",
    "[SONANT] 4\n",
    "[ENs] 4\n",
    "[MUSIC] 4\n",
    "君意 4\n",
    "+ 10\"\"\")\n",
    "jieba.load_userdict(\"user_dict.txt\")\n",
    "\n",
    "# import shutil\n",
    "# shutil.copytree(\"../input/dpcode0/DeepSpeechRecognition-master/\", \"./DeepSpeechRecognition-master/\")\n",
    "\n",
    "# os.listdir(\"./DeepSpeechRecognition-master/\")\n",
    "\n",
    "dev = pd.read_csv(\"./dataset/dev.csv\")\n",
    "test = pd.read_csv(\"./dataset/test.csv\")\n",
    "train = pd.read_csv(\"./dataset/train.csv\")\n",
    "\n",
    "# train.words.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len([i for i in dev.words if \"+\" in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lcut(x):\n",
    "    if x.startswith(\"[\"):\n",
    "        return [x]\n",
    "    return jieba.lcut(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en2cn = {'A': '诶','B': '必','C': '细','D': '地','E': '亿','F': 'f','G': '计',\n",
    "'H': 'h','I': '爱','J': '戒','K': '尅','L': 'l','M': 'm','N': '恩','O': '欧','P': '批','Q': 'q',\n",
    "'R': '儿','S': 's','T': '剃','U': '优','V': '微','W': 'z','X': 'x','Y': '外','Z': 'z'}\n",
    "\n",
    "en2cn_dict = {}\n",
    "for i in en2cn:\n",
    "    en2cn_dict[i] = lazy_pinyin(en2cn[i], style=style)[0]\n",
    "    en2cn_dict[i.lower()] = en2cn_dict[i]\n",
    "# load_single_dict(en2cn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def errorpy(words):\n",
    "    words = words.strip()\n",
    "    if words.isalpha() and len(words)==1:\n",
    "        return en2cn_dict[words]\n",
    "    elif len(words)>1:\n",
    "        print(words)\n",
    "        return [en2cn_dict[i]  if i.isalpha() and len(i)==1 else i for i in words.split(\" \")]                  \n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[UNK]\n",
      "app\n",
      "r n g im a teacher\n",
      "['12', 'ge4', '[UNK]', 'de', 'xiao3', 'app', 'tu4', 'zi', 'er2', 'en1', 'ji4', 'im', 'ei2', 'teacher']\n"
     ]
    }
   ],
   "source": [
    "print(lazy_pinyin('12个[UNK]的 小app兔子 r n g im a teacher ', style=style, errors=errorpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string, re\n",
    "# punctuation = string.punctuation + \"\"\"！？｡。＂＃＄％＆＇（）＊＋，－／：；＝＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘'‛“”„‟…‧﹏.\"\"\"\n",
    "punctuation = '!\"#$%&\\'()*+,-./:;=?@\\\\^_`{|}~' + \"\"\"！？｡。＂＃＄％＆＇（）＊＋，－／：；＝＠＼＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘'‛“”„‟…‧﹏.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load  dev.txt  data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 6086/6086 [00:00<00:00, 338997.80it/s]\n"
     ]
    }
   ],
   "source": [
    "read_files = [\"dev.txt\"]#[\"dev.csv\"]#   #[\"train.csv\"] #\n",
    "wav_lst = []\n",
    "pny_lst = []\n",
    "han_lst = []\n",
    "for file in read_files:\n",
    "    if \"csv\" in file:\n",
    "        data = pd.read_csv(\"./dataset/\"+file)\n",
    "        data = data.loc[~data.words.isin(['+', '[SONANT]', '[ENS]', '[*]', '[LAUGH]', '[MUSIC]'])]\n",
    "        data.words = data.words.apply(lambda x:re.sub(\"[{}]+\".format(punctuation), \" \", x).strip() )\n",
    "        data[\"wav_file\"] = data[\"Unnamed: 0\"].swifter.apply(lambda x: \"./dataset/train_bytes/wave_\"+str(x)+\".csv\")\n",
    "        data[\"pny\"] = data[\"words\"].swifter.apply(lambda x: lazy_pinyin(x, style=style, errors=errorpy))\n",
    "    else:\n",
    "        print('load ', file, ' data...')\n",
    "        sub_file = './' + file\n",
    "        with open(sub_file, 'r', encoding='utf8') as f:\n",
    "            data = f.readlines()\n",
    "        for line in tqdm(data):\n",
    "            wav_file, pny, han = line.split('\\t')\n",
    "            wav_lst.append(wav_file)\n",
    "            pny_lst.append(pny.split(' '))\n",
    "            han_lst.append(han.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_pinyin(data):\n",
    "    data = data.loc[~data.words.isin(['+', '[SONANT]', '[ENS]', '[*]', '[LAUGH]', '[MUSIC]'])]\n",
    "    data.loc[:, \"words\"] = data.words.swifter.apply(lambda x:re.sub(\"[{}]+\".format(punctuation), \" \", x).strip() )\n",
    "    data[\"wav_file\"] = data[\"Unnamed: 0\"].swifter.apply(lambda x: \"./dataset/train_bytes/wave_\"+str(x)+\".bin\")\n",
    "    data[\"pny\"] = data[\"words\"].swifter.apply(lambda x: lazy_pinyin(x, style=style, errors=errorpy))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7866de6e7eab4417bb4531c85aacdaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=116097, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d2316c750a48498d2d8503da4b38a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=116097, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9120b45b374a4d31af99348ac8b96c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=116097, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app\n",
      "olay\n",
      "olay\n",
      "p k\n",
      "m a c\n",
      "b e t\n",
      "a j\n",
      "a d\n",
      "a d\n",
      "a d\n",
      "z k\n",
      "mvp\n",
      "mvp\n",
      "mvp\n",
      "m v p\n",
      "low\n",
      "m v p\n",
      "pk\n",
      "nba\n",
      "nba\n",
      "logo\n",
      "nba\n",
      "ok\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "cba\n",
      "mvp\n",
      "mvp\n",
      "mvp\n",
      "mvp\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "cba\n",
      "mvp\n",
      "cba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "cba\n",
      "nba\n",
      "cba\n",
      "nba\n",
      "nba\n",
      "cba\n",
      "cba\n",
      "mvp\n",
      "nba\n",
      "cba\n",
      "A A\n",
      "D N A\n",
      "R N A\n",
      "qq\n",
      "vip\n",
      "n b a\n",
      "n b a\n",
      "n b a\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "vip\n",
      "vip\n",
      "buff\n",
      "buff\n",
      "buff\n",
      "buff\n",
      "solo\n",
      "solo\n",
      "solo\n",
      "adc\n",
      "adc\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "o k\n",
      "pk\n",
      "pk\n",
      "man\n",
      "out\n",
      "see sky\n",
      "papi\n",
      "papi\n",
      "q q\n",
      "q q\n",
      "y s l\n",
      "y s l\n",
      "iphone x iphone x s\n",
      "iphone\n",
      "iPhone\n",
      "cctv\n",
      "running\n",
      "gai\n",
      "rapper\n",
      "freestyle\n",
      "flow\n",
      "popping\n",
      "old school\n",
      "pk\n",
      "pk\n",
      "popping\n",
      "tv\n",
      "buff\n",
      "buff\n",
      "buff\n",
      "buff\n",
      "buff\n",
      "buff\n",
      "double kill\n",
      "biu\n",
      "biu\n",
      "w s a d\n",
      "w s a d\n",
      "oppo\n",
      "oppo\n",
      "buff\n",
      "boss\n",
      "man\n",
      "exo\n",
      "exo\n",
      "exo\n",
      "exo\n",
      "m m\n",
      "exo\n",
      "exo\n",
      "exo\n",
      "exo\n",
      "tfboys\n",
      "nine\n",
      "snh\n",
      "b b b b\n",
      "miniso\n",
      "b b\n",
      "b b\n",
      "c c\n",
      "b b\n",
      "b b\n",
      "b b\n",
      "b b\n",
      "kiko\n",
      "t f\n",
      "t f\n",
      "a j\n",
      "a j\n",
      "a j\n",
      "t f\n",
      "clean\n",
      "c l e a n\n",
      "bb\n",
      "c c\n",
      "cc\n",
      "w i s\n",
      "v i s\n",
      "m a c\n",
      "tfboys\n",
      "cosplay\n",
      "cosplay\n",
      "s n h four eight\n",
      "s n h four eight\n",
      "cosplay\n",
      "mv\n",
      "mv\n",
      "boss\n",
      "boss\n",
      "hi\n",
      "app\n",
      "exo\n",
      "mike\n",
      "man\n",
      "t f boys\n",
      "t f boys\n",
      "t f boys\n",
      "video\n",
      "angelababy\n",
      "a b\n",
      "angelababy\n",
      "iPhone x\n",
      "broke\n",
      "a c c a\n",
      "a c c a\n",
      "exo\n",
      "exo exo\n",
      "exo\n",
      "exo\n",
      "kbs\n",
      "part\n",
      "kbs\n",
      "monster\n",
      "demo\n",
      "demo\n",
      "exo\n",
      "sm\n",
      "sm\n",
      "kbs\n",
      "sm\n",
      "sm\n",
      "exo\n",
      "sm\n",
      "power\n",
      "sm\n",
      "b f\n",
      "b f\n",
      "b f\n",
      "n y s n y x\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "cctv\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "man\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "cuba\n",
      "cuba\n",
      "man\n",
      "man\n",
      "man\n",
      "get\n",
      "[ ][ ]\n",
      "mate\n",
      "pro\n",
      "pro\n",
      "pro\n",
      "mix\n",
      "mix\n",
      "mix\n",
      "mix\n",
      "if\n",
      "if\n",
      "g t\n",
      "g t\n",
      "a o e\n",
      "o k\n",
      "s p s\n",
      "c f\n",
      "c f\n",
      "r n g\n",
      "g two\n",
      "i g\n",
      "i g\n",
      "i g\n",
      "ipad\n",
      "q q\n",
      "x o\n",
      "x o\n",
      "m v\n",
      "chen\n",
      "c p\n",
      "c p\n",
      "qq\n",
      "po\n",
      "po\n",
      "po\n",
      "rain\n",
      "rain\n",
      "qq\n",
      "qq\n",
      "po\n",
      "balance\n",
      "pd\n",
      "balance\n",
      "balance\n",
      "e x o\n",
      "e x o\n",
      "h i p\n",
      "pk\n",
      "pk\n",
      "feel\n",
      "rose jack jack rose\n",
      "angelababy\n",
      "angelababy\n",
      "angelababy\n",
      "angelababy\n",
      "app\n",
      "app\n",
      "m a c\n",
      "m a c\n",
      "tfboys\n",
      "tfboys\n",
      "t v\n",
      "t v\n",
      "m i k e\n",
      "kiss me\n",
      "mike\n",
      "mike\n",
      "mike\n",
      "mike\n",
      "mike\n",
      "c p\n",
      "c p\n",
      "cf\n",
      "cs\n",
      "cf\n",
      "cf\n",
      "cf\n",
      "adc\n",
      "adc\n",
      "w w\n",
      "cd\n",
      "sky dancer\n",
      "sky dancer\n",
      "sky dancer\n",
      "sky dancer\n",
      "sky dancer\n",
      "bgm\n",
      "game over\n",
      "g g\n",
      "bug\n",
      "bug\n",
      "fpp\n",
      "tpp\n",
      "a m\n",
      "l g d\n",
      "godv\n",
      "r r\n",
      "u m p\n",
      "u m p\n",
      "u z i\n",
      "vector\n",
      "vector\n",
      "u m p\n",
      "u m p\n",
      "u m p\n",
      "a a k m\n",
      "a k m\n",
      "a k m\n",
      "m k\n",
      "m k\n",
      "scar\n",
      "d p\n",
      "groza\n",
      "a w m\n",
      "u m p\n",
      "m k\n",
      "m k\n",
      "m k\n",
      "m k\n",
      "m k\n",
      "k sks\n",
      "mini\n",
      "mini m mini\n",
      "m k\n",
      "a w m m\n",
      "q b u\n",
      "q b u\n",
      "s k s\n",
      "s k s\n",
      "v v s s\n",
      "v s s\n",
      "m k\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "a h c\n",
      "hold\n",
      "hold\n",
      "hold\n",
      "hold\n",
      "hold\n",
      "hold\n",
      "hold\n",
      "hold\n",
      "hold\n",
      "hold\n",
      "angela baby\n",
      "angela baby\n",
      "app\n",
      "app\n",
      "app\n",
      "yellow red pink\n",
      "yellow pink purple\n",
      "yellow\n",
      "red\n",
      "a b c d e f g\n",
      "vivo\n",
      "iphone x max\n",
      "vivo\n",
      "vivo z\n",
      "cp\n",
      "cp\n",
      "app\n",
      "app\n",
      "ok\n",
      "ok\n",
      "app\n",
      "app\n",
      "ppt\n",
      "app\n",
      "ok\n",
      "bug\n",
      "app\n",
      "app\n",
      "ok\n",
      "app\n",
      "app\n",
      "app\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "m b\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "app\n",
      "perfect\n",
      "cp\n",
      "ktv\n",
      "ktv\n",
      "ktv\n",
      "ktv\n",
      "ktv\n",
      "ipad\n",
      "q q\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "wifi\n",
      "solo\n",
      "solo\n",
      "solo\n",
      "solo\n",
      "solo\n",
      "solo\n",
      "lpl\n",
      "ol\n",
      "lol\n",
      "lpl\n",
      "lol\n",
      "rw\n",
      "rw\n",
      "rogue warriors\n",
      "xo\n",
      "gucci\n",
      "rng\n",
      "rng\n",
      "rng\n",
      "royal never giveup\n",
      "rng\n",
      "u z i\n",
      "p d d\n",
      "u z i\n",
      "u z i\n",
      "rng\n",
      "hold\n",
      "hold\n",
      "ktv\n",
      "qq\n",
      "q q\n",
      "q q\n",
      "ipad\n",
      "e x o\n",
      "e x o\n",
      "c p\n",
      "a p p\n",
      "open\n",
      "open\n",
      "open\n",
      "open\n",
      "c c\n",
      "qq\n",
      "s k t t\n",
      "p c\n",
      "r n g\n",
      "k two\n",
      "r ng\n",
      "r n g\n",
      "r n g\n",
      "u z i\n",
      "s k t\n",
      "faker\n",
      "s k t\n",
      "r n g\n",
      "i g\n",
      "i g\n",
      "r n g\n",
      "r n g\n",
      "w w w w\n",
      "d n a\n",
      "d n a\n",
      "d n a\n",
      "d n a\n",
      "d n a\n",
      "v i p\n",
      "wifi\n",
      "wifi\n",
      "wifi\n",
      "wifi\n",
      "wifi\n",
      "wifi\n",
      "wifi\n",
      "wifi\n",
      "wifi\n",
      "dj\n",
      "dj\n",
      "dj\n",
      "e x e exo\n",
      "t s\n",
      "tfboys\n",
      "amazing\n",
      "get\n",
      "CP\n",
      "cp\n",
      "a b c d\n",
      "country\n",
      "u f o\n",
      "office\n",
      "[ ][ ]\n",
      "qq\n",
      "angela baby\n",
      "[ ][ ]\n",
      "[ENS][ENS]\n",
      "sky\n",
      "qq\n",
      "qq\n",
      "k t v\n",
      "k t v\n",
      "q q\n",
      "q q\n",
      "v i p\n",
      "open\n",
      "[LAUGH][LAUGH]\n",
      "jack\n",
      "rose\n",
      "jack\n",
      "rose\n",
      "rose\n",
      "jack jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "rose\n",
      "jack\n",
      "rose\n",
      "rose\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "rose\n",
      "rose\n",
      "rose\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "jack\n",
      "m a c\n",
      "m a c\n",
      "m a c\n",
      "a j\n",
      "a j\n",
      "a j\n",
      "a j\n",
      "a j\n",
      "ppt\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "qq\n",
      "mvp\n",
      "vip\n",
      "vip\n",
      "vip\n",
      "vip\n",
      "party\n",
      "police\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "ok\n",
      "QQ\n",
      "m a t\n",
      "p h\n",
      "p h p h\n",
      "p h\n",
      "low\n",
      "running man\n",
      "m a c\n",
      "why\n",
      "mylefolen\n",
      "low\n",
      "low\n",
      "e d g e e d g\n",
      "e d g i g r m\n",
      "b p\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "r n g\n",
      "i g\n",
      "i g\n",
      "i g\n",
      "i g\n",
      "i g\n",
      "k p\n",
      "k p\n",
      "shy\n",
      "i g i g\n",
      "i g\n",
      "r n g r n g\n",
      "m a\n",
      "u z i\n",
      "u z i\n",
      "r n g\n",
      "i g\n",
      "i g\n",
      "k p\n",
      "shy\n",
      "k p\n",
      "k p\n",
      "ban\n",
      "k p\n",
      "i g\n",
      "a d c\n",
      "a d c\n",
      "e d g k p\n",
      "b o\n",
      "i g\n",
      "k p\n",
      "k p\n",
      "counter\n",
      "k p\n",
      "k p\n",
      "counter\n",
      "i g\n",
      "t p\n",
      "t p\n",
      "t p\n",
      "t p\n",
      "i g\n",
      "t p\n",
      "t p t p\n",
      "ban pick\n",
      "k p\n",
      "counter\n",
      "a p\n",
      "k t k t\n",
      "i g\n",
      "ban\n",
      "f n c c\n",
      "l c k\n",
      "e d g\n",
      "e d g\n",
      "e d g\n",
      "e d g e d g\n",
      "r n g\n",
      "k p\n",
      "k p\n",
      "k p\n",
      "k p\n",
      "q w\n",
      "q e a\n",
      "w q a a a e\n",
      "l p l\n",
      "i g\n",
      "i g i g i g\n",
      "roll\n",
      "k p\n",
      "k p\n",
      "i g\n",
      "k p\n",
      "m v p\n",
      "m v p\n",
      "m v p\n",
      "k p\n",
      "k p\n",
      "k p\n",
      "i g\n",
      "u z i\n",
      "a p\n",
      "r n g\n",
      "u z i\n",
      "u z i\n",
      "u z i\n",
      "m s i\n",
      "a p\n",
      "i g\n",
      "a d c\n",
      "a p\n",
      "b p\n",
      "counter\n",
      "a d c\n",
      "e w\n",
      "i g\n",
      "ban\n",
      "counter\n",
      "a d\n",
      "a d\n",
      "a d\n",
      "gank\n",
      "i g\n",
      "r n g\n",
      "r n g\n",
      "b o\n",
      "r n g\n",
      "ban pick\n",
      "r n g\n",
      "ban pick\n",
      "ban pick\n",
      "im a teacher\n",
      "h i v\n",
      "h i v\n",
      "v i p\n",
      "angelababy\n",
      "jasper\n",
      "jasper\n",
      "jasper\n",
      "jasper\n",
      "jasper\n",
      "jasper\n",
      "jasper\n",
      "jasper jasper\n",
      "jasper\n",
      "jasper\n",
      "angela baby\n",
      "angela baby\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "u z i\n",
      "a d c\n",
      "a d c\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "u z i\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "u z i\n",
      "u z i\n",
      "u z i\n",
      "b p\n",
      "u z i\n",
      "u z i\n",
      "a d c\n",
      "u z i\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "d c\n",
      "a d c\n",
      "bug\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "a d\n",
      "q q\n",
      "a d\n",
      "a d\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "a d\n",
      "a d c\n",
      "a d c\n",
      "a d c\n",
      "bug\n",
      "a d\n",
      "pk\n",
      "a d c\n",
      "a d c\n",
      "app\n",
      "app\n",
      "app\n",
      "app\n",
      "app\n",
      "app\n",
      "papi\n",
      "papi\n",
      "papi\n",
      "exo\n",
      "cpa\n",
      "cpa\n",
      "cpa\n",
      "cpa\n",
      "cpa\n",
      "cpa\n",
      "hold\n",
      "a b c d\n",
      "buy\n",
      "buy\n",
      "purchase\n",
      "purchase\n",
      "purchase\n",
      "r c h a s e\n",
      "i g\n",
      "g two g two\n",
      "b o\n",
      "b o\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "l e t m e\n",
      "u z i\n",
      "m i n g\n",
      "a d c\n",
      "a d c\n",
      "a d\n",
      "a d\n",
      "c a r r y\n",
      "a d c\n",
      "c a r r y\n",
      "r n g\n",
      "r n g\n",
      "g t w o\n",
      "i g\n",
      "g t w o\n",
      "u z i\n",
      "l p l\n",
      "m s i\n",
      "r n g\n",
      "l c k\n",
      "k t\n",
      "k t\n",
      "k t\n",
      "r n g\n",
      "g t w o\n",
      "g t w o\n",
      "g t w o\n",
      "g t w o c\n",
      "f f n a t i c\n",
      "i g\n",
      "r n g\n",
      "b p b p\n",
      "ban\n",
      "r n g\n",
      "b p\n",
      "b p\n",
      "ban\n",
      "ban\n",
      "ban\n",
      "ban\n",
      "ban\n",
      "r n g\n",
      "g t w o\n",
      "r n g\n",
      "u z i\n",
      "a d c\n",
      "c a s e\n",
      "g t w o\n",
      "adc\n",
      "g t w o\n",
      "u z i\n",
      "r n g\n",
      "i g\n",
      "i g\n",
      "r n g\n",
      "r n g\n",
      "l p l\n",
      "i g\n",
      "i g\n",
      "k t\n",
      "m s i\n",
      "i g\n",
      "r n g\n",
      "s k t\n",
      "k t\n",
      "i g\n",
      "i g\n",
      "f n a t i c\n",
      "f n a t i c\n",
      "a f r e e c a\n",
      "a f r e e c a\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "g t w o\n",
      "g t w o\n",
      "r n g\n",
      "g two\n",
      "i g\n",
      "i g\n",
      "r n g\n",
      "g t w o\n",
      "kawasaki\n",
      "t m k t m\n",
      "k t m\n",
      "k t m\n",
      "k t m\n",
      "r c\n",
      "r c\n",
      "k t m\n",
      "a b c d e\n",
      "b b a\n",
      "b b a\n",
      "b b a\n",
      "b b a\n",
      "polo\n",
      "polo\n",
      "polo\n",
      "ipad\n",
      "ipad\n",
      "ipad\n",
      "d k\n",
      "d k\n",
      "ok\n",
      "combo\n",
      "d k\n",
      "d d k\n",
      "d k\n",
      "nice\n",
      "l e\n",
      "hold\n",
      "hold\n",
      "gay\n",
      "q q\n",
      "q q\n",
      "[ ][ ]\n",
      "qq\n",
      "p g one\n",
      "cp\n",
      "cp\n",
      "cp\n",
      "cp\n",
      "a a\n",
      "a a\n",
      "qq\n",
      "idea\n",
      "qq\n",
      "ok\n",
      "no\n",
      "sorry\n",
      "b b k\n",
      "ktv\n",
      "ktv\n",
      "v i\n",
      "v i\n",
      "jasper\n",
      "tfboys\n",
      "tfboys\n",
      "ok ok\n",
      "cctv\n",
      "[ENS][ ]\n",
      "[ ][ ]\n",
      "hold\n",
      "pos\n",
      "ppt\n",
      "wifi\n",
      "wifi\n",
      "ppt\n",
      "plc\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "photo shop\n",
      "p s\n",
      "photo shop\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "office\n",
      "office\n",
      "office\n",
      "office\n",
      "word p p t\n",
      "excel excel\n",
      "v b\n",
      "a i\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "adobe\n",
      "adobe\n",
      "p s\n",
      "adobe\n",
      "p s\n",
      "a e a u a i\n",
      "a i\n",
      "a i\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "a i\n",
      "a i\n",
      "a e\n",
      "p s\n",
      "a i\n",
      "p s\n",
      "photo shop\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "adobe\n",
      "adobe\n",
      "p s\n",
      "adobe\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "p s\n",
      "adobe\n",
      "adobe p s\n",
      "adobe\n",
      "a i\n",
      "a u\n",
      "a u\n",
      "a c r\n",
      "i d\n",
      "i d\n",
      "a n\n",
      "a e\n",
      "fla\n",
      "fla\n",
      "flash\n",
      "adobe\n",
      "adobe\n",
      "adobe\n",
      "adobe\n",
      "adobe\n",
      "adobe\n",
      "p s\n",
      "flash\n",
      "adobe\n",
      "p s p s\n",
      "bug\n",
      "p s\n",
      "p s\n",
      "low\n",
      "a b c d\n",
      "a a a a a\n",
      "a b\n",
      "l i n e\n",
      "l i n\n",
      "l i n e\n",
      "t v\n",
      "mvp\n",
      "mvp\n",
      "mvp\n",
      "mvp\n",
      "ban\n",
      "ban\n",
      "cp\n",
      "cp\n",
      "cp\n",
      "cp\n",
      "o k o k\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "pro\n",
      "mate\n",
      "ios\n",
      "plus\n",
      "app\n",
      "max\n",
      "mix\n",
      "xe\n",
      "se\n",
      "se\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "ptsd\n",
      "ip\n",
      "ip\n",
      "walking dead\n",
      "walking dead\n",
      "capcom\n",
      "umbrella\n",
      "umbrella\n",
      "umbrella\n",
      "umbrella\n",
      "umbrella\n",
      "umbrella\n",
      "umbrella\n",
      "umbrella\n",
      "umbrella\n",
      "umbrella\n",
      "walking dead\n",
      "ip\n",
      "iphone x\n",
      "iphone x\n",
      "iphone x\n",
      "iphone x\n",
      "iphone\n",
      "iphone ten\n",
      "ten\n",
      "iphone\n",
      "x x s x s max\n",
      "iphone x\n",
      "iphone x\n",
      "c e o\n",
      "iphone x\n",
      "iphone\n",
      "i c d\n",
      "iphone x\n",
      "iphone x\n",
      "c d\n",
      "iphone\n",
      "l c d\n",
      "l c d\n",
      "l c d\n",
      "x s\n",
      "x s\n",
      "x s\n",
      "x s\n",
      "d touch\n",
      "d touch\n",
      "d touch\n",
      "d touch\n",
      "x s max\n",
      "x x\n",
      "x s\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "pro\n",
      "pro\n",
      "pro\n",
      "mate\n",
      "mat mate\n",
      "mate\n",
      "mate mate\n",
      "mate\n",
      "magic\n",
      "magic\n",
      "magic\n",
      "mate\n",
      "mate\n",
      "hello\n",
      "boos\n",
      "bug\n",
      "k p l\n",
      "a g\n",
      "a g\n",
      "a g\n",
      "a g\n",
      "r n g\n",
      "a d\n",
      "r n g\n",
      "a d\n",
      "u z i\n",
      "u z i\n",
      "r n g\n",
      "r n g\n",
      "u z i\n",
      "u z i\n",
      "u z i\n",
      "u z i\n",
      "u z i\n",
      "r n g\n",
      "r n g\n",
      "b o\n",
      "b o\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "s t\n",
      "s k t\n",
      "faker\n",
      "faker\n",
      "i g\n",
      "i g\n",
      "i g\n",
      "s k t\n",
      "k t\n",
      "s k t\n",
      "s k t\n",
      "i g\n",
      "s k t\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "r n g\n",
      "u z i\n",
      "u z i\n",
      "a d\n",
      "r n g\n",
      "u z i\n",
      "u z i\n",
      "u z i\n",
      "u z i\n",
      "do dota\n",
      "a d\n",
      "a d\n",
      "a d\n",
      "a p\n",
      "carry\n",
      "carry\n",
      "carry\n",
      "carry\n",
      "carry\n",
      "a d\n",
      "a d c a d c\n",
      "a d c\n",
      "carry\n",
      "a d\n",
      "a p\n",
      "a d\n",
      "r n g\n",
      "i g\n",
      "r n g\n",
      "r n g\n",
      "number one\n",
      "get\n",
      "get\n",
      "aj\n",
      "ktv\n",
      "ktv\n",
      "ktv\n",
      "ktv\n",
      "battle\n",
      "battle\n",
      "battle\n",
      "battle\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "ok\n",
      "get\n",
      "angelababy\n",
      "angelababy\n",
      "angelababy\n",
      "ok\n",
      "a i\n",
      "ai\n",
      "a i\n",
      "offer\n",
      "iphone\n",
      "mate\n",
      "mate\n",
      "mate\n",
      "tibet\n",
      "shift\n",
      "shift\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "mvp\n",
      "nba\n",
      "mvp\n",
      "mvp\n",
      "mvp\n",
      "nba\n",
      "mvp\n",
      "nba\n",
      "California\n",
      "nba\n",
      "nba\n",
      "nba\n",
      "jjr\n",
      "jr\n",
      "n b a\n",
      "flag\n",
      "sorry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "boss\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "harry\n",
      "v i p\n",
      "q q\n",
      "up\n",
      "up\n",
      "a j\n",
      "a j\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "g k h\n",
      "p p t\n",
      "k t v\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "q q\n",
      "surprise\n",
      "surprise\n",
      "iphone\n",
      "iphone\n",
      "iphone\n",
      "iphone\n",
      "iphone\n",
      "iphone\n",
      "windows phone\n",
      "oppo\n",
      "vivo\n",
      "vivo oppo\n",
      "note\n",
      "m x\n",
      "note\n",
      "metal\n",
      "ok\n",
      "t i\n",
      "t i\n",
      "i i\n",
      "i i\n",
      "t i\n",
      "t i\n",
      "c p u\n",
      "c p u\n",
      "c p u\n",
      "c p u\n",
      "c p u\n",
      "c p u\n",
      "i i\n",
      "low\n",
      "low\n",
      "g t\n",
      "g t\n",
      "g t\n",
      "ok\n",
      "g t\n",
      "g t\n",
      "h d\n",
      "g t s\n",
      "g t s\n",
      "h d\n",
      "h d\n",
      "g t\n",
      "g t s\n",
      "g t s\n",
      "g t s\n",
      "h d\n",
      "h d\n",
      "g g\n",
      "c p u\n",
      "low\n",
      "t i\n",
      "t i\n",
      "apple\n",
      "macbook\n",
      "macbook\n",
      "you jump i jump\n",
      "you jump i jump\n",
      "ok\n",
      "atm\n",
      "atm\n",
      "it\n",
      "qq\n",
      "qq\n",
      "ktv\n",
      "qq\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2109de97d8b46aa98f4571701d5dcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=6086, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded695a73d4b4e589efd3d9b6010a531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=6086, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fbf085ee504117933c9ccbdb5469ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=6086, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n",
      "dolphin\n",
      "monkey\n",
      "panda\n",
      "rabbit\n",
      "elephant\n",
      "tiger\n",
      "lion\n",
      "alligator\n",
      "Giraffe\n",
      "Giraffe\n",
      "nfc\n",
      "a i\n",
      "ai\n",
      "ai\n",
      "ai\n",
      "pro\n",
      "z z\n",
      "bose\n",
      "jbl\n",
      "bose\n",
      "u e\n",
      "m p\n",
      "m p\n",
      "m p\n",
      "m p\n",
      "hifi\n",
      "hifi\n",
      "hifi\n",
      "m p\n",
      "c d\n",
      "c d\n",
      "m p\n",
      "c d\n",
      "hifi\n",
      "hifi\n",
      "c d\n",
      "c d\n",
      "c d\n",
      "c d\n",
      "m p\n",
      "a p e\n",
      "f l a c\n",
      "jbl\n",
      "jbl\n",
      "jbl\n",
      "hdr\n",
      "tcl\n",
      "iphone\n",
      "oppo\n",
      "vivo\n",
      "oppo find\n",
      "vivo find\n",
      "vivo\n",
      "nex nex\n",
      "vivo\n",
      "vivo\n",
      "vivo\n",
      "google\n",
      "google\n",
      "lg\n",
      "tcl\n",
      "tcl htc\n",
      "google pixel\n",
      "google pixel\n",
      "google\n",
      "nexus\n",
      "ipad\n",
      "c c\n",
      "c c\n",
      "java\n",
      "d h a\n",
      "d h a\n",
      "d n a\n",
      "v c\n",
      "v c\n",
      "v c\n",
      "v c\n",
      "v c\n",
      "hello\n",
      "hello\n",
      "ok\n",
      "hello\n",
      "hello\n",
      "OK\n",
      "OK\n",
      "OK\n",
      "ok\n",
      "ok\n",
      "m v p\n",
      "i t\n",
      "i t\n",
      "XFun\n",
      "ok\n",
      "ok\n",
      "r n g\n",
      "p p k\n",
      "c s\n",
      "c s c f\n",
      "c f\n",
      "qq\n",
      "[UNK]\n",
      "c p\n",
      "c p\n",
      "[UNK]\n",
      "d i y\n",
      "over\n",
      "ip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = add_pinyin(train)\n",
    "dev_df = add_pinyin(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a486ad5bfb241eba32d76802b8d3c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=116097, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b35fc2483f4d9d9ab1a954aa0171df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=6086, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.pny = train_df.pny.swifter.apply(lambda x:\" \".join(x))\n",
    "dev_df.pny = dev_df.pny.swifter.apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "dev_df.wav_file = dev_df.apply(lambda x: \"./dataset/dev(SPK)/dev_byte(%s)/wave_\"%(x[\"speaker\"])+str(x[\"Unnamed: 0\"])+\".bin\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.loc[:, [\"wav_file\", \"pny\", \"words\"]].to_csv(\"train.txt\", index=False, header=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_df.loc[~dev_df.speaker.isna(), [\"wav_file\", \"pny\", \"words\"]].to_csv(\"dev.txt\", index=False, header=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import compute_fbank, multi_task, generate_fbank\n",
    "\n",
    "import time\n",
    "import multiprocessing as mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./dataset/dev.txt\", delimiter=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_file</th>\n",
       "      <th>pny</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/dev(SPK)/dev_byte(SPK001)/wave_1.bin</td>\n",
       "      <td>niu1 niu1 jin1 tian1 wo3 men liao2 shen2 me ne</td>\n",
       "      <td>妞妞 今天我们聊什么呢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/dev(SPK)/dev_byte(SPK002)/wave_2.bin</td>\n",
       "      <td>wo3 men jin1 tian1 liao2 dong4 wu4</td>\n",
       "      <td>我们今天聊动物</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/dev(SPK)/dev_byte(SPK001)/wave_3.bin</td>\n",
       "      <td>hao3 ba</td>\n",
       "      <td>好吧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/dev(SPK)/dev_byte(SPK001)/wave_5.bin</td>\n",
       "      <td>na4 ni3 shuo1 yi1 shuo1 dong4 wu4 ba</td>\n",
       "      <td>那你说一说动物吧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/dev(SPK)/dev_byte(SPK002)/wave_6.bin</td>\n",
       "      <td>a1 yi2 ni3 xi3 huan1 shen2 me</td>\n",
       "      <td>阿姨你喜欢什么</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         wav_file  \\\n",
       "0  ./dataset/dev(SPK)/dev_byte(SPK001)/wave_1.bin   \n",
       "1  ./dataset/dev(SPK)/dev_byte(SPK002)/wave_2.bin   \n",
       "2  ./dataset/dev(SPK)/dev_byte(SPK001)/wave_3.bin   \n",
       "3  ./dataset/dev(SPK)/dev_byte(SPK001)/wave_5.bin   \n",
       "4  ./dataset/dev(SPK)/dev_byte(SPK002)/wave_6.bin   \n",
       "\n",
       "                                              pny        words  \n",
       "0  niu1 niu1 jin1 tian1 wo3 men liao2 shen2 me ne  妞妞 今天我们聊什么呢  \n",
       "1              wo3 men jin1 tian1 liao2 dong4 wu4      我们今天聊动物  \n",
       "2                                         hao3 ba           好吧  \n",
       "3            na4 ni3 shuo1 yi1 shuo1 dong4 wu4 ba     那你说一说动物吧  \n",
       "4                   a1 yi2 ni3 xi3 huan1 shen2 me      阿姨你喜欢什么  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns = [\"wav_file\", \"pny\", \"words\"]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in os.listdir(\"./dataset/train_bytes/\"):\n",
    "    if \"npz\" not in i and \"bin\" not in i:\n",
    "        _path = os.path.join(\"./dataset/train_bytes/\", i)\n",
    "        os.rename(_path, _path + \".bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.24859839, 6.06366269, 6.34028129, ..., 0.74907302, 1.87378113,\n",
       "        2.41111297],\n",
       "       [5.4403597 , 6.27562947, 6.87843905, ..., 1.78649284, 2.7536022 ,\n",
       "        0.76069381],\n",
       "       [4.72121008, 5.54630119, 6.02107866, ..., 1.87753565, 0.9248445 ,\n",
       "        1.65966227],\n",
       "       ...,\n",
       "       [3.46930624, 4.14616927, 5.06861765, ..., 1.28698306, 2.21705445,\n",
       "        0.90436631],\n",
       "       [0.3783282 , 4.66558223, 5.3631227 , ..., 1.74361356, 1.98506984,\n",
       "        1.60256936],\n",
       "       [3.42243883, 4.17866339, 4.75218618, ..., 2.01441578, 2.030116  ,\n",
       "        2.20481057]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"./dataset/train_bytes/wave_873.npz\")[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0347b96bdb14e22a3d5a4258bf720b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=6085, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6085\n",
      "batch_num 304\n",
      "task 0 shape 304\n",
      "task 1 shape 304\n",
      "task 2 shape 304\n",
      "task 3 shape 304\n",
      "task 4 shape 304\n",
      "task 5 shape 304\n",
      "task 6 shape 304\n",
      "task 7 shape 304\n",
      "task 8 shape 304\n",
      "task 9 shape 304\n",
      "task 10 shape 304\n",
      "task 11 shape 304\n",
      "task 12 shape 304\n",
      "task 13 shape 304\n",
      "task 14 shape 304\n",
      "task 15 shape 304\n",
      "task 16 shape 304\n",
      "task 17 shape 304\n",
      "task 18 shape 304\n",
      "task 19 shape 309\n",
      "finished 20\n",
      "time 930 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 181.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6085\n"
     ]
    }
   ],
   "source": [
    "# def generate_fbank(x):\n",
    "#     data = compute_fbank(x)\n",
    "#     path = x.replace(\".csv\", \"\")\n",
    "#     if not os.path.exists(os.path.dirname(path)):\n",
    "#         print(\"making dir:\", os.path.dirname(path))\n",
    "#         os.makedirs(os.path.dirname(path))\n",
    "#     np.savez_compressed(path, data=data)\n",
    "#     return path\n",
    "\n",
    "# def multi_task(data, s_type):\n",
    "#     data[\"fbank_path\"] =  data['wav_file'].swifter.apply(lambda x: generate_fbank(x))\n",
    "#     return data\n",
    "\n",
    "train_files = []\n",
    "\n",
    "train_files = train_df.loc[~train_df.wav_file.swifter.apply(lambda x: os.path.exists(x.replace(\"bin\", \"npz\")))]\n",
    "# train\n",
    "t0 = time.time()\n",
    "N = train_files.shape[0]\n",
    "print(N)\n",
    "num_cpu = 20 # cpu数量\n",
    "pool = mlp.Pool(num_cpu)\n",
    "\n",
    "results = []\n",
    "batch_num = N // num_cpu\n",
    "print('batch_num',batch_num)\n",
    "for i in range(num_cpu):\n",
    "    if i == num_cpu-1:\n",
    "        offset = N\n",
    "    else:\n",
    "        offset = (i+1)*batch_num\n",
    "    task_train = train_files.iloc[i*batch_num : offset]\n",
    "    print('task',i,'shape',len(task_train))\n",
    "    result = pool.apply_async(multi_task,(task_train, 'train',))\n",
    "    results.append(result)\n",
    "pool.close()\n",
    "pool.join()\n",
    "print('finished',len(results))\n",
    "\n",
    "t1 = time.time()\n",
    "print('time', int(t1 - t0), 's')\n",
    "trs = pd.DataFrame()\n",
    "for result in tqdm(results):\n",
    "    trs = pd.concat([trs, result.get()])\n",
    "print(trs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_am_vocab(data):\n",
    "    vocab = []\n",
    "    for line in tqdm(data):\n",
    "        for pny in line:\n",
    "            if pny not in vocab:\n",
    "                vocab.append(pny)\n",
    "    vocab.append('_')\n",
    "    return vocab\n",
    "\n",
    "def mk_lm_pny_vocab(data):\n",
    "    vocab = ['<PAD>']\n",
    "    for line in tqdm(data):\n",
    "        for pny in line:\n",
    "            if pny not in vocab:\n",
    "                vocab.append(pny)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len({j for p in pny_lst for j in p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(mk_am_vocab(pny_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('make am vocab...')\n",
    "am_vocab_tr = mk_am_vocab(train_df.pny)\n",
    "print('make lm pinyin vocab...')\n",
    "pny_vocab_tr = mk_lm_pny_vocab(train_df.pny)\n",
    "print('make am vocab...')\n",
    "am_vocab_dev = mk_am_vocab(dev_df.pny)\n",
    "print('make lm pinyin vocab...')\n",
    "pny_vocab_dev = mk_lm_pny_vocab(dev_df.pny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in set(pny_vocab_tr):\n",
    "    if i.isalpha():\n",
    "        print(i)\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in set(pny_vocab_dev):\n",
    "    if i.isalpha():\n",
    "        print(i)\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha_list_tr = []\n",
    "for i in set(pny_vocab_tr):\n",
    "    if i.isalpha():\n",
    "        alpha_list_tr.append(i)\n",
    "alpha_list_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_alpha_list = []\n",
    "for i in set(pny_vocab_dev):\n",
    "    if i.isalpha():\n",
    "        dev_alpha_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"全是字母的：\", alpha_list_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"全是字母的：\", dev_alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 本地中文拼音库\n",
    "with open(\"pinyin.txt\", \"r\") as f:\n",
    "    pinyinLib = f.read().split(\"\\n\")\n",
    "\n",
    "en_list = []\n",
    "for i in alpha_list_tr:\n",
    "    if i not in pinyinLib and len(i)>0:\n",
    "        en_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_en_list = []\n",
    "for i in dev_alpha_list:\n",
    "    if i not in pinyinLib and len(i)>0:\n",
    "        dev_en_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"英文字母：\", en_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"英文字母：\", dev_en_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./pny_dict.json\", \"w\") as fw:\n",
    "    fw.write(json.dumps({\"train\": list(train_pny), \"dev\":list(dev_pny)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_Chinese(word):\n",
    "    for ch in word:\n",
    "        if '\\u4e00' <= ch <= '\\u9fff':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = []\n",
    "line = \"12个[UNK]的 小app兔子mike r n g im a   teacher \".split(' ')\n",
    "for patch in line:\n",
    "    if patch.encode(\"utf-8\").isalpha():\n",
    "        if patch not in vocab:\n",
    "            vocab.append(patch)\n",
    "    elif patch == \"[UNK]\":\n",
    "        print(patch)\n",
    "    else:\n",
    "        en_str = \"\"\n",
    "        for han in patch:\n",
    "            if not is_Chinese(han):\n",
    "                en_str += han\n",
    "            elif is_Chinese(han):            \n",
    "                if en_str != \"\" and en_str not in vocab:\n",
    "                    vocab.append(en_str)\n",
    "                    en_str = \"\"\n",
    "                if han not in vocab:\n",
    "                    vocab.append(han)\n",
    "            else:\n",
    "                print(\"ERROR:\", han)\n",
    "        if en_str != \"\" and en_str not in vocab:\n",
    "            vocab.append(en_str) \n",
    "            en_str = \"\"\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_lm_han_vocab(data):\n",
    "    vocab = ['<PAD>']\n",
    "    for line in tqdm(data):\n",
    "        if line in vocab:\n",
    "            continue\n",
    "        line = line.split(' ')\n",
    "        for patch in line:\n",
    "            if patch.encode(\"utf-8\").isalpha():\n",
    "                if patch not in vocab:\n",
    "                    vocab.append(patch)\n",
    "            elif patch == \"[UNK]\":\n",
    "                print(patch)\n",
    "            else:\n",
    "                en_str = \"\"\n",
    "                for han in patch:\n",
    "                    if not is_Chinese(han):\n",
    "                        en_str += han\n",
    "                    elif is_Chinese(han):            \n",
    "                        if en_str != \"\" and en_str not in vocab:\n",
    "                            vocab.append(en_str)\n",
    "                            en_str = \"\"\n",
    "                        if han not in vocab:\n",
    "                            vocab.append(han)\n",
    "                    else:\n",
    "                        print(\"ERROR:\", han)\n",
    "                if en_str != \"\" and en_str not in vocab:\n",
    "                    vocab.append(en_str) \n",
    "                    en_str = \"\"\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('make lm hanzi vocab...')\n",
    "han_vocab = mk_lm_han_vocab(train_df.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(dev_pny_vocab).difference(set(pny_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(set(han_vocab)),len(set(han_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
